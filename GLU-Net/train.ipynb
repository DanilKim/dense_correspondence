{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "from os import path as osp\n",
    "from termcolor import colored\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from datasets.training_dataset import HomoAffTps_Dataset\n",
    "from datasets.load_pre_made_dataset import PreMadeDataset\n",
    "from utils_training.optimize_GLUNet_with_adaptive_resolution import train_epoch, validate_epoch\n",
    "from models.our_models.GLUNet import GLUNet_model\n",
    "from utils_training.utils_CNN import load_checkpoint, save_checkpoint, boolean_string\n",
    "from tensorboardX import SummaryWriter\n",
    "from utils.image_transforms import ArrayToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Synthetic training dataset is already created and saved in disk ? default is False'\n",
    "pre_loaded_training_dataset =False,\n",
    "\n",
    "# 'path to directory containing original images for training if --pre_loaded_training_'\n",
    "# 'dataset is False or containing the synthetic pairs of training images and their '\n",
    "# 'corresponding flow fields if --pre_loaded_training_dataset is True'\n",
    "training_data_dir = \"\"\n",
    "\n",
    "# 'path to directory containing original images for validation if --pre_loaded_training_'\n",
    "# 'dataset is False or containing the synthetic pairs of validation images and their '\n",
    "# 'corresponding flow fields if --pre_loaded_training_dataset is True'\n",
    "evaluation_data_dir = \"\"\n",
    "\n",
    "snapshots =\"./snapshots\"\n",
    "\n",
    "# 'path to pre-trained model'\n",
    "pretrained=None,\n",
    "                       \n",
    "# Optimization parameters\n",
    "# 'learning rate'\n",
    "lr=0.0001\n",
    "\n",
    "# 'momentum constant'\n",
    "momentum=4e-4, \n",
    "\n",
    "# 'start epoch'\n",
    "start_epoch=-1\n",
    "\n",
    "# 'number of training epochs'\n",
    "n_epoch =200\n",
    "\n",
    "# 'training batch size'\n",
    "batch-size =16\n",
    "\n",
    "# 'number of parallel threads for dataloaders'\n",
    "n_threads = 8\n",
    "\n",
    "# 'weight decay constant'\n",
    "weight-decay=4e-4\n",
    "\n",
    "# 'div flow'\n",
    "div_flow=1.0\n",
    "\n",
    "# Pseudo-RNG seed'\n",
    "seed=1986\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets, pre-processing of the images is done within the network function !\n",
    "source_img_transforms = transforms.Compose([ArrayToTensor(get_float=False)])\n",
    "target_img_transforms = transforms.Compose([ArrayToTensor(get_float=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not pre_loaded_training_dataset:\n",
    "    # training dataset, created on the fly at each epoch\n",
    "    pyramid_param = [520] # means that we get the ground-truth flow field at this size\n",
    "    train_dataset = HomoAffTps_Dataset(image_path=training_data_dir,\n",
    "                                       csv_file=osp.join('datasets', 'csv_files',\n",
    "                                                     'homo_aff_tps_train_DPED_CityScape_ADE.csv'),\n",
    "                                       transforms=source_img_transforms,\n",
    "                                       transforms_target=target_img_transforms,\n",
    "                                       pyramid_param=pyramid_param,\n",
    "                                       get_flow=True,\n",
    "                                       output_size=(520, 520)   \n",
    "    # validation dataset\n",
    "    pyramid_param = [520]\n",
    "    val_dataset = HomoAffTps_Dataset(image_path=evaluation_data_dir,\n",
    "                                         csv_file=osp.join('datasets', 'csv_files',\n",
    "                                                           'homo_aff_tps_test_DPED_CityScape_ADE.csv'),\n",
    "                                         transforms=source_img_transforms,\n",
    "                                         transforms_target=target_img_transforms,\n",
    "                                         pyramid_param=pyramid_param,\n",
    "                                         get_flow=True,\n",
    "                                         output_size=(520, 520))\n",
    "else:\n",
    "        # If synthetic pairs were already created and saved to disk, run instead of 'train_dataset' the following.\n",
    "        # and replace args.training_data_dir by the root to folders containing images/ and flow/\n",
    "\n",
    "    flow_transform = transforms.Compose([ArrayToTensor()]) # just put channels first and put it to float\n",
    "    train_dataset, _ = PreMadeDataset(root=training_data_dir,\n",
    "                                      source_image_transform=source_img_transforms,\n",
    "                                      target_image_transform=target_img_transforms,\n",
    "                                      flow_transform=flow_transform,\n",
    "                                      co_transform=None,\n",
    "                                      split=1)  # only training\n",
    "    _, val_dataset = PreMadeDataset(root=evaluation_data_dir,\n",
    "                                        source_image_transform=source_img_transforms,\n",
    "                                        target_image_transform=target_img_transforms,\n",
    "                                        flow_transform=flow_transform,\n",
    "                                        co_transform=None,\n",
    "                                        split=0)  # only validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=n_threads)\n",
    "val_dataloader = DataLoader(val_dataset,\n",
    "                            batch_size=20,\n",
    "                            shuffle=False,\n",
    "                            num_workers=n_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "model = GLUNet_model(batch_norm=True, pyramid_type='VGG',\n",
    "                         div=div_flow, evaluation=False,\n",
    "                         consensus_network=False,\n",
    "                         cyclic_consistency=True,\n",
    "                         dense_connection=True,\n",
    "                         decoder_inputs='corr_flow_feat',\n",
    "                         refinement_at_all_levels=False,\n",
    "                         refinement_at_adaptive_reso=True)\n",
    "print(colored('==> ', 'blue') + 'GLU-Net created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pretrained:\n",
    "    # reload from pre_trained_model\n",
    "    model, optimizer, scheduler, start_epoch, best_val = load_checkpoint(model, optimizer, scheduler, filename=pretrained)\n",
    "    # now individually transfer the optimizer parts...\n",
    "    for state in optimizer.state.values():\n",
    "        for k, v in state.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                state[k] = v.to(device)\n",
    "    cur_snapshot = os.path.basename(os.path.dirname(pretrained))\n",
    "else:\n",
    "    if not os.path.isdir(snapshots):\n",
    "        os.mkdir(snapshots)\n",
    "    cur_snapshot = time.strftime('%Y_%m_%d_%H_%M')\n",
    "    if not osp.isdir(osp.join(snapshots, cur_snapshot)):\n",
    "        os.mkdir(osp.join(snapshots, cur_snapshot))\n",
    "    with open(osp.join(snapshots, cur_snapshot, 'args.pkl'), 'wb') as f:\n",
    "        pickle.dump(args, f)\n",
    "    best_val = -1\n",
    "    start_epoch = 0"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}