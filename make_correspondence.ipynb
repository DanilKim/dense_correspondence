{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named torchvision.transforms",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4ec7a38bcf85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named torchvision.transforms"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def default_loader(root, path_imgs, path_flo):\n",
    "    imgs = [os.path.join(root,path) for path in path_imgs]\n",
    "    flo = os.path.join(root,path_flo)\n",
    "    return [imread(img).astype(np.float32) for img in imgs],load_flo(flo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['clean/alley_1/frame_0001.png', 'clean/alley_1/frame_0002.png'], 'flow/alley_1/frame_0001.flo'], [['clean/alley_1/frame_0007.png', 'clean/alley_1/frame_0008.png'], 'flow/alley_1/frame_0007.flo'])\n"
     ]
    }
   ],
   "source": [
    "A1 = sorted(glob.glob(os.path.join('sintel','flow','alley_1','*.flo')))\n",
    "images = []\n",
    "for flow_map in A1:\n",
    "    flow_map = os.path.relpath(flow_map, os.path.join('sintel','flow'))\n",
    "    \n",
    "    scene_dir, filename = os.path.split(flow_map)\n",
    "    no_ext_filename = os.path.splitext(filename)[0]\n",
    "    prefix, frame_nb = no_ext_filename.split('_')\n",
    "    frame_nb = int(frame_nb)\n",
    "    \n",
    "    img1 = os.path.join('clean', scene_dir, '{}_{:04d}.png'.format(prefix, frame_nb))\n",
    "    img2 = os.path.join('clean', scene_dir, '{}_{:04d}.png'.format(prefix, frame_nb+1))\n",
    "    flow_map = os.path.join('flow', flow_map)\n",
    "    \n",
    "    if not (os.path.isfile(os.path.join('sintel',img1)) and os.path.isfile(os.path.join('sintel',img2))):\n",
    "        continue\n",
    "    images.append([[img1,img2],flow_map])\n",
    "    \n",
    "split_values = np.random.uniform(0,1,len(images)) < 0.8\n",
    "train_samples = [sample for sample, split in zip(images, split_values) if split]\n",
    "test_samples = [sample for sample, split in zip(images, split_values) if not split]\n",
    "\n",
    "print(train_samples[0], test_samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-28990df7ec65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m input_transform = transforms.Compose([\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mflow_transforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArrayToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.45\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.432\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.411\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m ])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transforms' is not defined"
     ]
    }
   ],
   "source": [
    "input_transform = transforms.Compose([\n",
    "    flow_transforms.ArrayToTensor(),\n",
    "    transforms.Normalize(mean=[0,0,0], std=[255,255,255]),\n",
    "    transforms.Normalize(mean=[0.45,0.432,0.411], std=[1,1,1])\n",
    "])\n",
    "target_transform = transforms.Compose([\n",
    "    flow_transforms.ArrayToTensor(),\n",
    "    transforms.Normalize(mean=[0,0],std=[args.div_flow,args.div_flow])\n",
    "])\n",
    "## sparse ##\n",
    "co_transform = flow_transforms.Compose([\n",
    "    flow_transforms.RandomCrop((320,448)),\n",
    "    flow_transforms.RandomVerticalFlip(),\n",
    "    flow_transforms.RandomHorizontalFlip()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root = 'sintel'\n",
    "index = 0\n",
    "\n",
    "inputs, target = train_samples[index] # or test_samples (path_list)\n",
    "inputs, target = default_loader(root, inputs, target)\n",
    "\n",
    "if self.co_transform is not None:\n",
    "    inputs, target = self.co_transform(inputs, target)\n",
    "if self.transform is not None:\n",
    "    inputs[0] = self.transform(inputs[0])\n",
    "    inputs[1] = self.transform(inputs[1])\n",
    "if self.target_transform is not None:\n",
    "    target = self.target_transform(target)\n",
    "    \n",
    "print(inputs, target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
