{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import scipy\n",
    "import torch\n",
    "import numpy as np\n",
    "import flow_transforms\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.functional import grid_sample\n",
    "from imageio import imread\n",
    "import random\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ExtractDataset:\n",
    "    def __init__(self, root, scene_dir_list, data_type, pair_crit='random', margin=None, thres=None):\n",
    "        self.root = root\n",
    "        self.type = data_type\n",
    "        self.scene_dir_list = scene_dir_list\n",
    "        self.data = self.get_data(scene_dir_list)\n",
    "        self.pair_crit = pair_crit\n",
    "        self.margin = margin\n",
    "        self.thres = thres\n",
    "        if margin is None:\n",
    "            self.save_dir = os.path.join(root, 'extracted_pairs', self.type, pair_crit)\n",
    "        else:\n",
    "            self.save_dir = os.path.join(root, 'extracted_pairs', self.type, pair_crit + '_' + str(margin) + '_' +str(thres))\n",
    "        \n",
    "        \n",
    "    def load_flo(self, path):\n",
    "        with open(path, 'rb') as f:\n",
    "            magic = np.fromfile(f, np.float32, count=1)\n",
    "            assert(202021.25 == magic),'Magic number incorrect. Invalid .flo file'\n",
    "            h = np.fromfile(f, np.int32, count=1)[0]\n",
    "            w = np.fromfile(f, np.int32, count=1)[0]\n",
    "            data = np.fromfile(f, np.float32, count=2*w*h)\n",
    "        # Reshape data into 3D array (columns, rows, bands)\n",
    "        data2D = np.resize(data, (w, h, 2))\n",
    "        return data2D\n",
    "    \n",
    "    \n",
    "    def default_loader(self, root, path_img, path_flo, path_occ):\n",
    "        #imgs = [os.path.join(root,path) for path in path_imgs]\n",
    "        img = os.path.join(root,path_img)\n",
    "        if path_flo is not None:\n",
    "            flo = self.load_flo(os.path.join(root,path_flo))\n",
    "            occ = imread(os.path.join(root,path_occ))\n",
    "        else:\n",
    "            flo = None; occ = None;\n",
    "        return imread(img).astype(np.float32), flo, occ\n",
    "        #return [imread(img).astype(np.float32) for img in imgs], self.load_flo(flo), imread(occ)\n",
    "        \n",
    "\n",
    "    def save_flo(self, filename, flow):\n",
    "        TAG_STRING = b'PIEH'\n",
    "        # torch.Size([436, 1024, 2])\n",
    "        height, width, nBands = np.shape(flow)\n",
    "        \n",
    "        u = flow[: , : , 0]\n",
    "        v = flow[: , : , 1]\n",
    "        \n",
    "        height, width = u.shape\n",
    "        f = open(filename,'wb')\n",
    "        f.write(TAG_STRING)\n",
    "        np.array(width).astype(np.int32).tofile(f)\n",
    "        np.array(height).astype(np.int32).tofile(f)\n",
    "        tmp = np.zeros((height, width*nBands))\n",
    "        tmp[:,np.arange(width)*2] = u\n",
    "        tmp[:,np.arange(width)*2 + 1] = v\n",
    "        tmp.astype(np.float32).tofile(f)\n",
    "        f.close()\n",
    "        \n",
    "    \n",
    "    def save_pair(self, scene_name, start_num, end_num, start_img, end_img, occ_mask, flow_map):\n",
    "        path = os.path.join(self.save_dir, scene_name, 'start_'+str(start_num), 'end_'+str(end_num))\n",
    "        if not(os.path.isdir(path)):\n",
    "            os.makedirs(path)\n",
    "                        \n",
    "        imageio.imwrite(path+'/source.png', start_img.astype(np.uint8))\n",
    "        imageio.imwrite(path+'/target.png', end_img.astype(np.uint8))\n",
    "        imageio.imwrite(path+'/occlusion.png', occ_mask.numpy().astype(np.uint8))\n",
    "        self.save_flo(path+'/flow.flo', flow_map)\n",
    "        \n",
    "    \n",
    "    def get_data(self, scene_dir_list):\n",
    "        whole_file = []\n",
    "        for scene_dir in self.scene_dir_list:\n",
    "            single_dir_file = []\n",
    "            filelist = sorted(glob.glob(os.path.join(self.root,'flow',scene_dir,'*.flo')))\n",
    "            for flow_map in filelist:\n",
    "                flow_map = os.path.relpath(flow_map, os.path.join(self.root,'flow'))\n",
    "                \n",
    "                scene_dir, filename = os.path.split(flow_map)\n",
    "                no_ext_filename     = os.path.splitext(filename)[0]\n",
    "                prefix,    frame_nb = no_ext_filename.split('_')\n",
    "                frame_nb = int(frame_nb)\n",
    "                \n",
    "                occ_mask = os.path.join('occlusions', scene_dir, '{}_{:04d}.png'.format(prefix, frame_nb))\n",
    "                flow_map = os.path.join('flow', flow_map)\n",
    "                \n",
    "                img = os.path.join(self.type, scene_dir, '{}_{:04d}.png'.format(prefix, frame_nb))\n",
    "                if (os.path.isfile(os.path.join(self.root, img))):\n",
    "                    single_dir_file.append([img, flow_map, occ_mask])\n",
    "            \n",
    "            ## Add the last frame\n",
    "            img = os.path.join(self.type, scene_dir, '{}_{:04d}.png'.format(prefix, frame_nb+1))\n",
    "            if (os.path.isfile(os.path.join(self.root, img))):\n",
    "                single_dir_file.append([img, None, None])\n",
    "            \n",
    "            whole_file.append(single_dir_file)\n",
    "            \n",
    "        return whole_file\n",
    "    \n",
    "    \n",
    "    def extract_data(self):\n",
    "        if not(os.path.isdir(self.save_dir)):\n",
    "            os.makedirs(os.path.join(self.save_dir))\n",
    "            \n",
    "        for dir_num, dir_list in enumerate(self.data): # per scene directory\n",
    "            \n",
    "            scene_name = self.scene_dir_list[dir_num]\n",
    "            scene_data = self.data[dir_num]\n",
    "            \n",
    "            for prev_frame, file in enumerate(dir_list): # per start_frame in a scene \n",
    "                start_frame = prev_frame + 1\n",
    "                self.get_flo(scene_name, int(start_frame), len(dir_list), scene_data)\n",
    "                    \n",
    "                    \n",
    "    def get_flo(self, scene_name, start_frame, end_frame, train_samples):\n",
    "        start_img, _, _ = train_samples[start_frame-1]\n",
    "        start_img, _, _ = self.default_loader(self.root, start_img, None, None)\n",
    "        height, width, _ = start_img.shape\n",
    "        \n",
    "        ## Grid Location Point (x,y) matrix of size H X W\n",
    "        Y, X = torch.meshgrid(torch.arange(0, height), torch.arange(0, width))\n",
    "        Grid = torch.stack((X, Y), 2).float()\n",
    "        \n",
    "        ## Survived points in start frame image.  H x W\n",
    "        survived_mask = torch.ones(height, width)    \n",
    "\n",
    "        ## new_Grid as transformed pixel location, according to each pixel location in source frame\n",
    "        new_Grid = Grid.clone()\n",
    "        new_Grid_norm = torch.zeros(Grid.size()).unsqueeze(0)\n",
    "\n",
    "        for ind in range(start_frame, end_frame):\n",
    "            imgs, target, occ_mask = train_samples[ind-1]\n",
    "            target = torch.from_numpy(self.load_flo(os.path.join(self.root, target)))   ## Flow annotation. H x W x 2\n",
    "            occ_mask = torch.from_numpy(imread(os.path.join(self.root, occ_mask))).float() / 255    ## Occlusion mask. H x W\n",
    "    \n",
    "            if ind == start_frame:\n",
    "                warped_flow = target.permute(2,0,1)\n",
    "                warped_occ_mask = occ_mask\n",
    "            else:\n",
    "                ## Warping Occlusion Mask\n",
    "                warped_flow     = grid_sample(target.permute(2,0,1).unsqueeze(0),\n",
    "                                      new_Grid_norm, mode='nearest',\n",
    "                                      align_corners=True)[0]\n",
    "                ## Warping Flow information\n",
    "                warped_occ_mask = grid_sample(occ_mask[(None,)*2 + (...,)], \n",
    "                                      new_Grid_norm, mode='nearest', \n",
    "                                      align_corners=True)[0][0]\n",
    "\n",
    "            survived_mask = survived_mask * (1 - warped_occ_mask)\n",
    "    \n",
    "            new_Grid[:,:,0] = torch.clamp((new_Grid[:,:,0] + warped_flow[0,:,:]), 0, width-1)\n",
    "            new_Grid[:,:,1] = torch.clamp((new_Grid[:,:,1] + warped_flow[1,:,:]), 0, height-1)\n",
    "    \n",
    "            new_Grid_norm[:,:,:,0] = 2.0*new_Grid[:,:,0].clone() / max(width-1,1)-1.0       \n",
    "            new_Grid_norm[:,:,:,1] = 2.0*new_Grid[:,:,1].clone() / max(height-1,1)-1.0\n",
    "            \n",
    "            flow_map = new_Grid - Grid\n",
    "            \n",
    "            survived_grid = (survived_mask == 1).nonzero().transpose(0,1)\n",
    "            survived_points = Grid[survived_grid[0], survived_grid[1]].long().transpose(0,1)\n",
    "            pointwise_flows = flow_map[survived_grid[0], survived_grid[1]].transpose(0,1)\n",
    "            \n",
    "            #if survived_points.size(1) < (height - 4) * width * 0.1:\n",
    "            #    continue\n",
    "            if getattr(self, self.pair_crit+'_criterion')(survived_points, pointwise_flows):\n",
    "                end_img, _, _ = train_samples[ind] \n",
    "                end_img, _, _ = self.default_loader(self.root, end_img, None, None)\n",
    "                self.save_pair(scene_name, start_frame, ind+1, start_img[2:-2,:,:], end_img[2:-2,:,:],\\\n",
    "                               (1-survived_mask[2:-2,:])*255, flow_map[2:-2,:,:])\n",
    "    \n",
    "        #### Get Dense Flow Field ####\n",
    "        flow = new_Grid - Grid\n",
    "\n",
    "        inputs, target, mask = train_samples[start_frame-1]\n",
    "        inputs, _, _ = self.default_loader(self.root, inputs, target, mask)\n",
    "        outputs, target, occ_mask = train_samples[end_frame-1]    \n",
    "        outputs, _, _ = self.default_loader(self.root, outputs, target, occ_mask)\n",
    "        \n",
    "        #if start_frame == 15:\n",
    "        #    self.visualize(inputs, outputs, start_frame, end_frame, new_Grid_norm, survived_mask)\n",
    "        #return inputs, outputs, flow, survived_mask\n",
    "   \n",
    "\n",
    "    def mag_criterion(self, source_points, flow):\n",
    "        magnitude = flow.norm(p=2, dim=0)\n",
    "        magnitude = magnitude - magnitude.mean()\n",
    "        #magnitude = magnitude.pow(2)\n",
    "        return (float((magnitude > self.margin).sum()) / float(source_points.size(1))) > self.thres\n",
    "    \n",
    "    \n",
    "    def random_criterion(self, *args):\n",
    "        return (random.random() < 0.9)\n",
    "    \n",
    "    def all_criterion(self, *args):\n",
    "        return True\n",
    "        \n",
    "        \n",
    "    def visualize(self, src, tar, start_frame, end_frame, new_Grid_norm, survived):\n",
    "        height, width, _ = tar.shape\n",
    "        src = torch.from_numpy(src).permute(2,0,1).unsqueeze(0)\n",
    "        tar = torch.from_numpy(tar).permute(2,0,1).unsqueeze(0)\n",
    "        \n",
    "        warped_target = grid_sample(tar, new_Grid_norm, mode='nearest', align_corners=True)\n",
    "        warped_target = warped_target * survived + 255 * (1 - survived) \n",
    "        \n",
    "        fig = plt.figure(figsize=(15,15))\n",
    "        ax1 = fig.add_subplot(3,1,1)\n",
    "        ax1.set_title('Frame <%d>'% start_frame, fontsize=20)\n",
    "        ax1.axis(\"off\")\n",
    "        ax1.imshow(src[0].permute(1,2,0).numpy()/255)\n",
    "        ax2 = fig.add_subplot(3,1,2)\n",
    "        ax2.set_title('Frame <%d>'% end_frame, fontsize=20)\n",
    "        ax2.axis(\"off\")\n",
    "        ax2.imshow(tar[0].permute(1,2,0).numpy()/255)\n",
    "        ax3 = fig.add_subplot(3,1,3)\n",
    "        ax3.set_title('Warped From <%d> to <%d>'% (end_frame, start_frame), fontsize=20)\n",
    "        ax3.axis(\"off\")\n",
    "        ax3.imshow(warped_target[0].permute(1,2,0).numpy()/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scene_list = os.listdir(os.path.join('sintel', 'random_style'))\n",
    "#scene_list = ['ambush_2', 'temple_2', 'alley_1']\n",
    "Test = ExtractDataset('sintel', scene_list, 'random_style', 'all')\n",
    "#Test = ExtractDataset('sintel', scene_list, 'random_style', 'all')\n",
    "#Test1 = ExtractDataset('sintel', scene_list, 'clean', 'mag', 10, 0.2)\n",
    "#Test2 = ExtractDataset('sintel', scene_list, 'clean', 'mag', 20, 0.1)\n",
    "#Test3 = ExtractDataset('sintel', scene_list, 'clean', 'mag', 20, 0.3)\n",
    "#Test4 = ExtractDataset('sintel', scene_list, 'clean', 'mag', 10, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Test.extract_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22085\n"
     ]
    }
   ],
   "source": [
    "dataDir = Test.save_dir\n",
    "cnt = 0\n",
    "for sceneDir in os.listdir(dataDir):\n",
    "    for startDir in os.listdir(os.path.join(dataDir, sceneDir)):\n",
    "        for endDir in os.listdir(os.path.join(dataDir, sceneDir, startDir)):\n",
    "            cnt += 1\n",
    "\n",
    "print(cnt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pwcnet",
   "language": "python",
   "name": "pwcnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
