{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import scipy\n",
    "import torch\n",
    "import numpy as np\n",
    "import flow_transforms\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.functional import grid_sample\n",
    "from imageio import imread\n",
    "import random\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractDataset:\n",
    "    def __init__(self, root, scene_dir_list, data_type, save_dir=\"./save\"):\n",
    "        self.root = root\n",
    "        self.type = data_type\n",
    "        self.scene_dir_list = scene_dir_list\n",
    "        self.data = self.get_data(scene_dir_list)\n",
    "        self.save_dir = save_dir\n",
    "        \n",
    "        \n",
    "    def load_flo(self, path):\n",
    "        with open(path, 'rb') as f:\n",
    "            magic = np.fromfile(f, np.float32, count=1)\n",
    "            assert(202021.25 == magic),'Magic number incorrect. Invalid .flo file'\n",
    "            h = np.fromfile(f, np.int32, count=1)[0]\n",
    "            w = np.fromfile(f, np.int32, count=1)[0]\n",
    "            data = np.fromfile(f, np.float32, count=2*w*h)\n",
    "        # Reshape data into 3D array (columns, rows, bands)\n",
    "        data2D = np.resize(data, (w, h, 2))\n",
    "        return data2D\n",
    "    \n",
    "    \n",
    "    def default_loader(self, root, path_img, path_flo, path_occ):\n",
    "        #imgs = [os.path.join(root,path) for path in path_imgs]\n",
    "        img = os.path.join(root,path_img)\n",
    "        if path_flo is not None:\n",
    "            flo = self.load_flo(os.path.join(root,path_flo))\n",
    "            occ = imread(os.path.join(root,path_occ))\n",
    "        else:\n",
    "            flo = None; occ = None;\n",
    "        return imread(img).astype(np.float32), flo, occ\n",
    "        #return [imread(img).astype(np.float32) for img in imgs], self.load_flo(flo), imread(occ)\n",
    "        \n",
    "\n",
    "    def save_flo(self, filename, flow):\n",
    "        TAG_STRING = b'PIEH'\n",
    "        # torch.Size([436, 1024, 2])\n",
    "        height, width, nBands = np.shape(flow)\n",
    "        \n",
    "        u = flow[: , : , 0]\n",
    "        v = flow[: , : , 1]\n",
    "        \n",
    "        height, width = u.shape\n",
    "        f = open(filename,'wb')\n",
    "        f.write(TAG_STRING)\n",
    "        np.array(width).astype(np.int32).tofile(f)\n",
    "        np.array(height).astype(np.int32).tofile(f)\n",
    "        tmp = np.zeros((height, width*nBands))\n",
    "        tmp[:,np.arange(width)*2] = u\n",
    "        tmp[:,np.arange(width)*2 + 1] = v\n",
    "        tmp.astype(np.float32).tofile(f)\n",
    "        f.close()\n",
    "        \n",
    "    \n",
    "    def get_data(self, scene_dir_list):\n",
    "        whole_file = []\n",
    "        for scene_dir in self.scene_dir_list:\n",
    "            single_dir_file = []\n",
    "            filelist = sorted(glob.glob(os.path.join(self.root,'flow',scene_dir,'*.flo')))\n",
    "            for flow_map in filelist:\n",
    "                flow_map = os.path.relpath(flow_map, os.path.join(self.root,'flow'))\n",
    "                \n",
    "                scene_dir, filename = os.path.split(flow_map)\n",
    "                no_ext_filename     = os.path.splitext(filename)[0]\n",
    "                prefix,    frame_nb = no_ext_filename.split('_')\n",
    "                frame_nb = int(frame_nb)\n",
    "                \n",
    "                occ_mask = os.path.join('occlusions', scene_dir, '{}_{:04d}.png'.format(prefix, frame_nb))\n",
    "                flow_map = os.path.join('flow', flow_map)\n",
    "                \n",
    "                img = os.path.join('clean', scene_dir, '{}_{:04d}.png'.format(prefix, frame_nb))\n",
    "                if (os.path.isfile(os.path.join(self.root, img))):\n",
    "                    single_dir_file.append([img, flow_map, occ_mask])\n",
    "            \n",
    "            ## Add the last frame\n",
    "            img = os.path.join('clean', scene_dir, '{}_{:04d}.png'.format(prefix, frame_nb+1))\n",
    "            if (os.path.isfile(os.path.join(self.root, img))):\n",
    "                single_dir_file.append([img, None, None])\n",
    "            \n",
    "            whole_file.append(single_dir_file)\n",
    "            \n",
    "        return whole_file\n",
    "    \n",
    "    \n",
    "    def extract_data(self):\n",
    "        if not(os.path.isdir(self.save_dir)):\n",
    "            os.makedirs(os.path.join(self.save_dir))\n",
    "            \n",
    "        for dir_num, dir_list in enumerate(self.data): # per scene directory\n",
    "            \n",
    "            scene_name = self.scene_dir_list[dir_num]\n",
    "            scene_data = self.data[dir_num]\n",
    "            \n",
    "            #### start_frame  =  cnt + 1,  (cnt \\in [0, number_of_frames-5])\n",
    "            #### end_frames   =  randomly choose 'how_many_pick \\in [2, number_of_frames - start_frame - 2]'\n",
    "            ####                 numbers from [start_frame + 2, number_of_frames]\n",
    "            \n",
    "            for cnt, file in enumerate(dir_list): # per start_frame in a scene \n",
    "                if((cnt + 4) == len(dir_list)) :\n",
    "                    break\n",
    "                how_many_pick = random.randint(2, min(len(dir_list)-cnt-3, int(len(dir_list)/6)))\n",
    "                selected_ends = self.get_random_num(cnt+1, len(dir_list), how_many_pick)\n",
    "                start_num = cnt + 1      # int(file[0].split('/')[2].split('.')[0].split('_')[1])\n",
    "                        \n",
    "                for end_idx, end_num in enumerate(selected_ends): \n",
    "                    start_img, end_img, flow_map, survived_mask = \\\n",
    "                                self.get_flo(int(start_num), int(end_num), scene_data)\n",
    "                    occ_mask = (1 - survived_mask) * 255\n",
    "                    \n",
    "                    path = os.path.join(self.save_dir, scene_name, 'start_'+str(start_num), 'end_'+str(end_num))\n",
    "                    if not(os.path.isdir(path)):\n",
    "                        os.makedirs(path)\n",
    "                        \n",
    "                    imageio.imwrite(path+'/source.png', start_img.astype(np.uint8))\n",
    "                    imageio.imwrite(path+'/target.png', end_img.astype(np.uint8))\n",
    "                    imageio.imwrite(path+'/occlusion.png', occ_mask.numpy().astype(np.uint8))\n",
    "                    self.save_flo(path+'/flow.flo', flow_map)\n",
    "                    \n",
    "                    \n",
    "    def get_flo(self, start_frame, end_frame, train_samples):\n",
    "        inputs, target, mask = train_samples[start_frame-1]\n",
    "        inputs, target, mask = self.default_loader(self.root, inputs, target, mask)\n",
    "        height, width, _ = target.shape\n",
    "        \n",
    "        ## Grid Location Point (x,y) matrix of size H X W\n",
    "        Y, X = torch.meshgrid(torch.arange(0, height), torch.arange(0, width))\n",
    "        Grid = torch.stack((X, Y), 2).float()\n",
    "        \n",
    "        \n",
    "        ## Survived points in start frame image.  H x W\n",
    "        survived_mask = torch.ones(height, width)    \n",
    "\n",
    "        ## new_Grid as transformed pixel location, according to each pixel location in source frame\n",
    "        new_Grid = Grid.clone()\n",
    "        new_Grid_norm = torch.zeros(Grid.size()).unsqueeze(0)\n",
    "\n",
    "        for ind in range(start_frame, end_frame):\n",
    "            imgs, target, occ_mask = train_samples[ind-1]\n",
    "            target = torch.from_numpy(self.load_flo(os.path.join(self.root, target)))   ## Flow annotation. H x W x 2\n",
    "            occ_mask = torch.from_numpy(imread(os.path.join(self.root, occ_mask))).float() / 255    ## Occlusion mask. H x W\n",
    "    \n",
    "            if ind == start_frame:\n",
    "                warped_flow = target.permute(2,0,1)\n",
    "                warped_occ_mask = occ_mask\n",
    "            else:\n",
    "                ## Warping Occlusion Mask\n",
    "                warped_flow     = grid_sample(target.permute(2,0,1).unsqueeze(0),\n",
    "                                      new_Grid_norm, mode='nearest',\n",
    "                                      align_corners=True)[0]\n",
    "                ## Warping Flow information\n",
    "                warped_occ_mask = grid_sample(occ_mask[(None,)*2 + (...,)], \n",
    "                                      new_Grid_norm, mode='nearest', \n",
    "                                      align_corners=True)[0][0]\n",
    "\n",
    "            survived_mask = survived_mask * (1 - warped_occ_mask)\n",
    "    \n",
    "            new_Grid[:,:,0] = torch.clamp((new_Grid[:,:,0] + warped_flow[0,:,:]), 0, width-1)\n",
    "            new_Grid[:,:,1] = torch.clamp((new_Grid[:,:,1] + warped_flow[1,:,:]), 0, height-1)\n",
    "    \n",
    "            new_Grid_norm[:,:,:,0] = 2.0*new_Grid[:,:,0].clone() / max(width-1,1)-1.0       \n",
    "            new_Grid_norm[:,:,:,1] = 2.0*new_Grid[:,:,1].clone() / max(height-1,1)-1.0\n",
    "    \n",
    "        #### Get Dense Flow Field ####\n",
    "        flow = new_Grid - Grid\n",
    "\n",
    "        inputs, target, mask = train_samples[start_frame-1]\n",
    "        inputs, _, _ = self.default_loader(self.root, inputs, target, mask)\n",
    "        outputs, target, occ_mask = train_samples[end_frame-1]    \n",
    "        outputs, _, _ = self.default_loader(self.root, outputs, target, occ_mask)\n",
    "        \n",
    "        #if start_frame == 15:\n",
    "        #    self.visualize(inputs, outputs, start_frame, end_frame, new_Grid_norm, survived_mask)\n",
    "        return inputs, outputs, flow, survived_mask\n",
    "   \n",
    "                \n",
    "    def get_random_num(self, start, finish, num):\n",
    "        if(start >= finish) : print('finish number is same or less than start num');return -1\n",
    "        if(num <= 1) : print('The number of data requires bigger then one'); return -1\n",
    "        return sorted(random.sample(range(start+2, finish+1), num))\n",
    "        \n",
    "        \n",
    "    def visualize(self, src, tar, start_frame, end_frame, new_Grid_norm, survived):\n",
    "        height, width, _ = tar.shape\n",
    "        src = torch.from_numpy(src).permute(2,0,1).unsqueeze(0)\n",
    "        tar = torch.from_numpy(tar).permute(2,0,1).unsqueeze(0)\n",
    "        \n",
    "        warped_target = grid_sample(tar, new_Grid_norm, mode='nearest', align_corners=True)\n",
    "        warped_target = warped_target * survived + 255 * (1 - survived) \n",
    "        \n",
    "        fig = plt.figure(figsize=(15,15))\n",
    "        ax1 = fig.add_subplot(3,1,1)\n",
    "        ax1.set_title('Frame <%d>'% start_frame, fontsize=20)\n",
    "        ax1.axis(\"off\")\n",
    "        ax1.imshow(src[0].permute(1,2,0).numpy()/255)\n",
    "        ax2 = fig.add_subplot(3,1,2)\n",
    "        ax2.set_title('Frame <%d>'% end_frame, fontsize=20)\n",
    "        ax2.axis(\"off\")\n",
    "        ax2.imshow(tar[0].permute(1,2,0).numpy()/255)\n",
    "        ax3 = fig.add_subplot(3,1,3)\n",
    "        ax3.set_title('Warped From <%d> to <%d>'% (end_frame, start_frame), fontsize=20)\n",
    "        ax3.axis(\"off\")\n",
    "        ax3.imshow(warped_target[0].permute(1,2,0).numpy()/255)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = ExtractDataset('sintel', ['alley_1', 'ambush_4', 'temple_2'], 'clean')\n",
    "#Test = ExtractDataset('sintel', ['alley_1'], 'clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test.extract_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
