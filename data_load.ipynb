{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import scipy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import flow_transforms\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from imageio import imread\n",
    "\n",
    "def load_flo(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        magic = np.fromfile(f, np.float32, count=1)\n",
    "        assert(202021.25 == magic),'Magic number incorrect. Invalid .flo file'\n",
    "        h = np.fromfile(f, np.int32, count=1)[0]\n",
    "        w = np.fromfile(f, np.int32, count=1)[0]\n",
    "        data = np.fromfile(f, np.float32, count=2*w*h)\n",
    "    # Reshape data into 3D array (columns, rows, bands)\n",
    "    data2D = np.resize(data, (w, h, 2))\n",
    "    return data2D\n",
    "\n",
    "def default_loader(root, path_imgs, path_flo, path_occ):\n",
    "    imgs = [os.path.join(root,path) for path in path_imgs]\n",
    "    flo = os.path.join(root,path_flo)\n",
    "    occ = os.path.join(root,path_occ)\n",
    "    return [imread(img).astype(np.float32) for img in imgs], load_flo(flo), imread(occ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "for flow_map in sorted(glob.glob(os.path.join('sintel','flow','ambush_4','*.flo'))):\n",
    "    flow_map = os.path.relpath(flow_map, os.path.join('sintel','flow'))\n",
    "    \n",
    "    scene_dir, filename = os.path.split(flow_map)\n",
    "    no_ext_filename = os.path.splitext(filename)[0]\n",
    "    prefix, frame_nb = no_ext_filename.split('_')\n",
    "    frame_nb = int(frame_nb)\n",
    "    \n",
    "    img1 = os.path.join('clean', scene_dir, '{}_{:04d}.png'.format(prefix, frame_nb))\n",
    "    img2 = os.path.join('clean', scene_dir, '{}_{:04d}.png'.format(prefix, frame_nb+1))\n",
    "    occ_mask = os.path.join('occlusions', scene_dir, '{}_{:04d}.png'.format(prefix, frame_nb))\n",
    "    flow_map = os.path.join('flow', flow_map)\n",
    "    \n",
    "    if not (os.path.isfile(os.path.join('sintel',img1)) and os.path.isfile(os.path.join('sintel',img2))):\n",
    "        continue\n",
    "    images.append([[img1,img2], flow_map, occ_mask])\n",
    "\n",
    "split_factor = 1.1     ## ratio of train split\n",
    "split_values = np.random.uniform(0,1,len(images)) < split_factor\n",
    "train_samples = [sample for sample, split in zip(images, split_values) if split]\n",
    "test_samples = [sample for sample, split in zip(images, split_values) if not split]\n",
    "\n",
    "#print(train_samples[0], test_samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root = 'sintel'\n",
    "#index = 8\n",
    "\n",
    "#inputs, target, mask = train_samples[index] # or test_samples (path_list)\n",
    "#print(mask)\n",
    "\n",
    "#import matplotlib.image as mpimg\n",
    "#img1 = mpimg.imread(os.path.join(root, inputs[0]))\n",
    "#img2 = mpimg.imread(os.path.join(root, inputs[1]))\n",
    "#mask = mpimg.imread(os.path.join(root, mask))\n",
    "#mask = np.repeat(np.expand_dims(mask, axis=2), 3, axis=2)\n",
    "#print(img1.max())\n",
    "\n",
    "#fig = plt.figure()\n",
    "#a = fig.add_subplot(3, 1, 1)\n",
    "#imgplot = plt.imshow(img1)\n",
    "#a = fig.add_subplot(3, 1, 2)\n",
    "#imgplot = plt.imshow(img2)\n",
    "#a = fig.add_subplot(3, 1, 3)\n",
    "#imgplot = plt.imshow(mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_frame = 15\n",
    "end_frame = 23\n",
    "consistency_param = 50\n",
    "moving_param = 0  ## 0.5\n",
    "\n",
    "inputs, target, mask = train_samples[start_frame]\n",
    "inputs, target, mask = default_loader(root, inputs, target, mask)\n",
    "target = torch.from_numpy(target)\n",
    "\n",
    "width = target.size(1)\n",
    "height = target.size(0)\n",
    "\n",
    "X = torch.Tensor([[range(height)]*width]).transpose(1,2)\n",
    "Y = torch.Tensor([[range(width)]*height])\n",
    "Grid = torch.cat([X,Y], 0).permute(1, 2, 0)\n",
    "\n",
    "offset = torch.zeros(height, width, 2)\n",
    "magnitude = torch.zeros(height, width, 2)\n",
    "source_grid = torch.ones(height, width)\n",
    "\n",
    "new_Grid = Grid.clone()\n",
    "for ind in range(start_frame, end_frame):\n",
    "    _, target, mask = train_samples[ind]\n",
    "    target = torch.from_numpy(load_flo(os.path.join(root, target)))\n",
    "    mask = torch.from_numpy(imread(os.path.join(root, mask))).float()\n",
    "    \n",
    "    #new_Grid[:,:,0] = torch.clamp((new_Grid + target.int())[:,:,0], 0, height-1)\n",
    "    #new_Grid[:,:,1] = torch.clamp((new_Grid + target.int())[:,:,1], 0, width-1)\n",
    "    \n",
    "    new_Grid[:,:,0] = 2.0*new_Grid[:,:,0].clone() / max(height-1,1)-1.0\n",
    "    new_Grid[:,:,1] = 2.0*new_Grid[:,:,1].clone() / max(width-1,1)-1.0\n",
    "    \n",
    "    new_mask = nn.functional.grid_sample(mask.unsqueeze(2).unsqueeze(0), new_Grid.unsqueeze(0), align_corners=True)\n",
    "    source_grid = source_grid * (1 - new_mask[0])\n",
    "    #magnitude = magnitude + target.abs()\n",
    "\n",
    "outputs, target, mask = train_samples[end_frame]    \n",
    "outputs, _, mask = default_loader(root, outputs, target, mask)\n",
    "\n",
    "source_points = (source_grid == 1).nonzero().transpose(0,1)\n",
    "target_points = new_Grid[source_points[0], source_points[1]].long().transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################################\n",
    "###############    Valid Pixel Selection   ###############\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(magnitude[:,:,0].max(), magnitude[:,:,1].max())\n",
    "moving_pixels = ((magnitude[:,:,0] > height * moving_param) + (magnitude[:,:,1] > width * moving_param)).int()  ## H x W\n",
    "source_points = moving_pixels.nonzero().transpose(0,1)   ## 2 x num_points\n",
    "\n",
    "target_X = torch.clamp((Grid + offset.int())[:,:,0], 0, height-1)   ## H x W\n",
    "target_Y = torch.clamp((Grid + offset.int())[:,:,1], 0, width-1)    ## H x W\n",
    "target_Grid = torch.cat([target_X.unsqueeze(2), target_Y.unsqueeze(2)], 2)   ## H x W x 2\n",
    "\n",
    "target_points = target_Grid[source_points[0], source_points[1]].long().transpose(0,1) ##  2 x num_points\n",
    "\n",
    "source_image = torch.from_numpy(inputs[0])  ## H x W x 3\n",
    "target_image = torch.from_numpy(outputs[1])  ## H x W x 3\n",
    "\n",
    "source_value = source_image[source_points[0], source_points[1]]    ## num_points x 3\n",
    "target_value = target_image[target_points[0], target_points[1]]    ## num_points x 3\n",
    "\n",
    "diff = (source_value - target_value).norm(p=2, dim=1)\n",
    "consistent_points = (diff < 100).nonzero().squeeze()  # 1 x num_con_points\n",
    "print(consistent_points.size())\n",
    "\n",
    "source_points = source_points.transpose(0,1)[consistent_points]  # 2 x num_con_points\n",
    "target_points = target_points.transpose(0,1)[consistent_points]  # 2 x num_con_points\n",
    "\n",
    "print(source_points.transpose(0,1), target_points.transpose(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################################################\n",
    "################   Image Preprocessing   ################\n",
    "#########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "####### Data Pre-processing #######\n",
    "\n",
    "input_transform = transforms.Compose([\n",
    "    flow_transforms.ArrayToTensor(),\n",
    "    transforms.Normalize(mean=[0,0,0], std=[255,255,255]),\n",
    "    transforms.Normalize(mean=[0.45,0.432,0.411], std=[1,1,1])\n",
    "])\n",
    "target_transform = transforms.Compose([\n",
    "    flow_transforms.ArrayToTensor(),\n",
    "    transforms.Normalize(mean=[0,0],std=[20,20])\n",
    "])\n",
    "## sparse ##\n",
    "co_transform = flow_transforms.Compose([\n",
    "    flow_transforms.RandomCrop((320,448)),\n",
    "    flow_transforms.RandomVerticalFlip(),\n",
    "    flow_transforms.RandomHorizontalFlip()\n",
    "])\n",
    "\n",
    "print(inputs[0].shape, target.shape)   ### Compare before & after data pre-processing ###\n",
    "if co_transform is not None:\n",
    "    inputs, target = co_transform(inputs, target)\n",
    "if input_transform is not None:\n",
    "    inputs[0] = input_transform(inputs[0])\n",
    "    inputs[1] = input_transform(inputs[1])\n",
    "if target_transform is not None:\n",
    "    target = target_transform(target)\n",
    "\n",
    "print(inputs[0][0,100:107,100:107])\n",
    "print(target[0].max(), target[1].max())\n",
    "print(inputs[0].size(), target.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pwcnet",
   "language": "python",
   "name": "pwcnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
