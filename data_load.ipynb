{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import scipy\n",
    "import torch\n",
    "import numpy as np\n",
    "import flow_transforms\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.functional import grid_sample\n",
    "from imageio import imread\n",
    "import random\n",
    "import imageio\n",
    "\n",
    "def load_flo(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        magic = np.fromfile(f, np.float32, count=1)\n",
    "        assert(202021.25 == magic),'Magic number incorrect. Invalid .flo file'\n",
    "        h = np.fromfile(f, np.int32, count=1)[0]\n",
    "        w = np.fromfile(f, np.int32, count=1)[0]\n",
    "        data = np.fromfile(f, np.float32, count=2*w*h)\n",
    "    # Reshape data into 3D array (columns, rows, bands)\n",
    "    data2D = np.resize(data, (w, h, 2))\n",
    "    return data2D\n",
    "\n",
    "def default_loader(root, path_imgs, path_flo, path_occ):\n",
    "    imgs = [os.path.join(root,path) for path in path_imgs]\n",
    "    flo = os.path.join(root,path_flo)\n",
    "    occ = os.path.join(root,path_occ)\n",
    "    return [imread(img).astype(np.float32) for img in imgs], load_flo(flo), imread(occ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ExtractDataset:\n",
    "    def __init__(self, root, scene_dir_list, data_type, save_dir=\"./save\"):\n",
    "        self.root = root\n",
    "        self.type = data_type\n",
    "        self.scene_dir_list = scene_dir_list\n",
    "        self.data = self.get_data(scene_dir_list)\n",
    "        self.save_dir = save_dir\n",
    "        self.pair_data = self.get_data(scene_dir_list, True)\n",
    "        \n",
    "    def load_flo(self, path):\n",
    "        with open(path, 'rb') as f:\n",
    "            magic = np.fromfile(f, np.float32, count=1)\n",
    "            assert(202021.25 == magic),'Magic number incorrect. Invalid .flo file'\n",
    "            h = np.fromfile(f, np.int32, count=1)[0]\n",
    "            w = np.fromfile(f, np.int32, count=1)[0]\n",
    "            data = np.fromfile(f, np.float32, count=2*w*h)\n",
    "        # Reshape data into 3D array (columns, rows, bands)\n",
    "        data2D = np.resize(data, (w, h, 2))\n",
    "        return data2D\n",
    "    \n",
    "    def default_loader(self, root, path_imgs, path_flo, path_occ):\n",
    "        imgs = [os.path.join(root,path) for path in path_imgs]\n",
    "        flo = os.path.join(root,path_flo)\n",
    "        occ = os.path.join(root,path_occ)\n",
    "        return [imread(img).astype(np.float32) for img in imgs], self.load_flo(flo), imread(occ)\n",
    "        \n",
    "\n",
    "    def save_flo(self, filename, flow):\n",
    "        TAG_STRING = b'PIEH'\n",
    "        # torch.Size([436, 1024, 2])\n",
    "        height, width, nBands = np.shape(flow)\n",
    "        \n",
    "        u = flow[: , : , 0]\n",
    "        v = flow[: , : , 1]\n",
    "        \n",
    "        height, width = u.shape\n",
    "        f = open(filename,'wb')\n",
    "        f.write(TAG_STRING)\n",
    "        np.array(width).astype(np.int32).tofile(f)\n",
    "        np.array(height).astype(np.int32).tofile(f)\n",
    "        tmp = np.zeros((height, width*nBands))\n",
    "        tmp[:,np.arange(width)*2] = u\n",
    "        tmp[:,np.arange(width)*2 + 1] = v\n",
    "        tmp.astype(np.float32).tofile(f)\n",
    "        f.close()\n",
    "        \n",
    "    \n",
    "    def get_data(self, scene_dir_list, is_pair=False):\n",
    "        whole_file = []\n",
    "        for scene_dir in self.scene_dir_list:\n",
    "            single_dir_file = []\n",
    "            filelist = sorted(glob.glob(os.path.join(self.root,'flow',scene_dir,'*.flo')))\n",
    "            for flow_map in filelist:\n",
    "                flow_map = os.path.relpath(flow_map, os.path.join('sintel','flow'))\n",
    "                \n",
    "                scene_dir, filename = os.path.split(flow_map)\n",
    "                no_ext_filename = os.path.splitext(filename)[0]\n",
    "                prefix, frame_nb = no_ext_filename.split('_')\n",
    "                frame_nb = int(frame_nb)\n",
    "                \n",
    "                occ_mask = os.path.join('occlusions', scene_dir, '{}_{:04d}.png'.format(prefix, frame_nb))\n",
    "                flow_map = os.path.join('flow', flow_map)\n",
    "                \n",
    "                if(is_pair==False) : \n",
    "                    img = os.path.join(self.type, scene_dir, '{}_{:04d}.png'.format(prefix, frame_nb))\n",
    "                    if not (os.path.isfile(os.path.join('sintel',img))):\n",
    "                        continue\n",
    "                    single_dir_file.append([img, flow_map, occ_mask])\n",
    "                    \n",
    "                else:\n",
    "                    img1 = os.path.join('clean', scene_dir, '{}_{:04d}.png'.format(prefix, frame_nb))\n",
    "                    img2 = os.path.join('clean', scene_dir, '{}_{:04d}.png'.format(prefix, frame_nb+1))\n",
    "                    if not (os.path.isfile(os.path.join('sintel',img1)) and os.path.isfile(os.path.join('sintel',img2))):\n",
    "                        continue\n",
    "                    whole_file.append([[img1, img2], flow_map, occ_mask])\n",
    "                    \n",
    "            if(is_pair==False):\n",
    "                whole_file.append(single_dir_file)\n",
    "            \n",
    "        return whole_file\n",
    "    \n",
    "    def extract_data(self):\n",
    "        if not(os.path.isdir(self.save_dir)):\n",
    "            os.makedirs(os.path.join(self.save_dir))\n",
    "            \n",
    "        for dir_num, dir_list in enumerate(self.data): # per directory\n",
    "            \n",
    "            tmp = self.get_data(self.scene_dir_list[dir_num], True)\n",
    "            \n",
    "            for cnt, file in enumerate(dir_list): # data num\n",
    "                if((cnt + 4) == len(dir_list)) :\n",
    "                    break\n",
    "                how_many_pick = random.randint(2, len(dir_list)-cnt-3)\n",
    "                selected = self.get_random_num(cnt+1, len(dir_list)+1, how_many_pick)\n",
    "                start_num =int(file[0].split('/')[2].split('.')[0].split('_')[1])\n",
    "                \n",
    "                if not(os.path.isdir(os.path.join(self.save_dir, str(start_num)))):\n",
    "                        os.makedirs(os.path.join(self.save_dir, str(start_num)))\n",
    "                        \n",
    "                for sub_num, file_num in enumerate(selected): \n",
    "                    start_img, end_img, flow_map, occ_mask = self.get_flo(int(start_num), int(file_num), tmp)\n",
    "                    \n",
    "                    if not(os.path.isdir(os.path.join(self.save_dir, str(start_num), str(sub_num)))):\n",
    "                        os.makedirs(os.path.join(self.save_dir, str(start_num), str(sub_num)))\n",
    "                    path = os.path.join(self.save_dir, str(start_num), str(sub_num))\n",
    "                    imageio.imwrite(path+'/start.png', start_img.astype(np.uint8))\n",
    "                    imageio.imwrite(path+'/end.png', end_img.astype(np.uint8))\n",
    "                    imageio.imwrite(path+'/occlusion.png', occ_mask.numpy().astype(np.uint8))\n",
    "                    self.save_flo(path+'/flow.flo', flow_map)\n",
    "                    \n",
    "                    \n",
    "    def get_flo(self, start, end, train_samples):\n",
    "        start_frame = start\n",
    "        end_frame = end\n",
    "        inputs, target, mask = train_samples[start_frame]\n",
    "        inputs, target, mask = self.default_loader(self.root, inputs, target, mask)\n",
    "        height, width, _ = target.shape\n",
    "        \n",
    "        ## Grid Location Point (x,y) matrix of size H X W\n",
    "        Y, X = torch.meshgrid(torch.arange(0, height), torch.arange(0, width))\n",
    "        Grid = torch.stack((X, Y), 2).float()\n",
    "        \n",
    "        ## Survived points in start frame image.  H x W\n",
    "        survived_mask = torch.zeros(height, width).int() ## 0 for not vanished 1 for vanished  \n",
    "        \n",
    "        ## new_Grid as transformed pixel location, according to each pixel location in source frame\n",
    "        new_Grid = Grid.clone()\n",
    "        \n",
    "        for cnt, ind in enumerate(range(start_frame, end_frame)):\n",
    "            imgs, target, occ_mask = train_samples[ind]\n",
    "            \n",
    "            # target shape : torch.Size([436, 1024, 2])\n",
    "            target = torch.from_numpy(self.load_flo(os.path.join(self.root, target)))   ## Flow annotation. H x W x 2   \n",
    "            occ_mask = torch.from_numpy(imread(os.path.join(self.root, occ_mask))).int()\n",
    "    \n",
    "            survived_mask = survived_mask | occ_mask  ## whenever 1 is detected, remain it.\n",
    "        \n",
    "            new_Grid[:,:,0] = torch.clamp((new_Grid[:,:,0] + target[:,:,0]), 0, width-1)\n",
    "            new_Grid[:,:,1] = torch.clamp((new_Grid[:,:,1] + target[:,:,1]), 0, height-1)\n",
    "                \n",
    "        inputs, target, mask = train_samples[start_frame]\n",
    "        inputs, _, _ = self.default_loader(self.root, inputs, target, mask)\n",
    "        outputs, target, occ_mask = train_samples[end_frame]    \n",
    "        outputs, _, _ = self.default_loader(self.root, outputs, target, occ_mask)\n",
    "        return inputs[0], outputs[0], new_Grid, survived_mask\n",
    "   \n",
    "                \n",
    "    def get_random_num(self, start, finish, num):\n",
    "        if(start >= finish) : print('finish number is same or less than start num');return -1\n",
    "        if(num <= 1) : print('The number of data requires bigger then one'); return -1\n",
    "        return sorted(random.sample(range(start+2, finish+1), num))\n",
    "        \n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = ExtractDataset('sintel', ['alley_1', 'ambush_4', 'temple_2'], 'clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test.extract_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
